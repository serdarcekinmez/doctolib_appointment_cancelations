{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Other models and their metrics results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model= KNeighborsClassifier()\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "k_values = range(1, 20)\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['euclidean','minkowski']\n",
    "param_grid= {'n_neighbors': k_values, 'weights': weights, 'metric': metric}\n",
    "\n",
    "model_knn= GridSearchCV(model, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2)\n",
    "\n",
    "model_knn.fit(scaled_X_train, y_train)\n",
    "\n",
    "best_model= model_knn.best_estimator_.get_params()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "best_model = model_knn.best_estimator_\n",
    "\n",
    "best_pred = best_model.predict(scaled_X_test)\n",
    "\n",
    "print(classification_report(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.98      0.88     26525\n",
    "           1       0.38      0.05      0.09      6634\n",
    "\n",
    "    accuracy                           0.79     33159\n",
    "   macro avg       0.59      0.51      0.49     33159\n",
    "weighted avg       0.72      0.79      0.72     33159\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###RandomForest\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred= classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.89      0.85     26525\n",
    "           1       0.33      0.23      0.27      6634\n",
    "\n",
    "    accuracy                           0.75     33159\n",
    "   macro avg       0.58      0.56      0.56     33159\n",
    "weighted avg       0.72      0.75      0.74     33159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###RNF Metrics\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "prec = precision_score(y_test, y_pred)\n",
    "\n",
    "rec = recall_score(y_test, y_pred)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(f\"Model Performance Metrics:\")\n",
    "print(f\"  Accuracy: {acc:.2f}\")\n",
    "print(f\"  Precision: {prec:.2f}\")\n",
    "print(f\"  Recall: {rec:.2f}\")\n",
    "print(f\"  F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Performance Metrics:\n",
    "  Accuracy: 0.80\n",
    "  Precision: 0.33\n",
    "  Recall: 0.02\n",
    "  F1-Score: 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "gbm_model = xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1)\n",
    "\n",
    "gbm_model.fit(scaled_X_train, y_train)\n",
    "\n",
    "# make predictions on test set\n",
    "gbm_y_pred = gbm_model.predict(scaled_X_test)\n",
    "gbm_y_pred_prob = gbm_model.predict_proba(scaled_X_test)[:, 1]\n",
    "\n",
    "# calculate evaluation metrics\n",
    "gbm_accuracy = accuracy_score(y_test, gbm_y_pred)\n",
    "gbm_precision = precision_score(y_test, gbm_y_pred)\n",
    "gbm_recall = recall_score(y_test, gbm_y_pred)\n",
    "gbm_f1_score = f1_score(y_test, gbm_y_pred)\n",
    "gbm_auc_roc_score = roc_auc_score(y_test, gbm_y_pred_prob)\n",
    "\n",
    "# print evaluation metrics\n",
    "print(\"GBM Model Metrics:\")\n",
    "print(\"Accuracy: \", gbm_accuracy)\n",
    "print(\"Precision: \", gbm_precision)\n",
    "print(\"Recall: \", gbm_recall)\n",
    "print(\"F1 Score: \", gbm_f1_score)\n",
    "print(\"AUC-ROC Score: \", gbm_auc_roc_score)\n",
    "\n",
    "GBM Model Metrics:\n",
    "Accuracy:  0.7995416025815012\n",
    "Precision:  0.40298507462686567\n",
    "Recall:  0.004069942719324691\n",
    "F1 Score:  0.008058498731532606\n",
    "AUC-ROC Score:  0.692889853969654"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
